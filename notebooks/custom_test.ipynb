{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffd1e5da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-05-29 15:07:30,146-root] - Loading model microsoft/phi-2 with device:cuda, device_map:auto, torch_dtype:torch.bfloat16\n",
      "[2025-05-29 15:07:31,349-accelerate.utils.modeling] - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d5fecbcf41864092acc65544e079044a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-05-29 15:07:33,416-root] - Loading model microsoft/phi-2 with device:cuda, device_map:auto, torch_dtype:torch.bfloat16\n",
      "[2025-05-29 15:07:33,605-accelerate.utils.modeling] - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee0ec8b5deb64c6088096f43592c8ae4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-05-29 15:07:36,369-accelerate.big_modeling] - Some parameters are on the meta device because they were offloaded to the cpu.\n"
     ]
    }
   ],
   "source": [
    "from syncode import Syncode\n",
    "\n",
    "grammar = \"\"\" start: month \" \" day \n",
    "              \n",
    "              day: /[1-9]/ | /[1-2][0-9]/ | /3[0-1]/\n",
    "              \n",
    "              month: \"January\" | \"February\" | \"March\" | \"April\" | \"May\" | \"June\" | \"July\" | \"August\" | \"September\" | \"October\" | \"November\" | \"December\"\n",
    "\"\"\"\n",
    "\n",
    "model_name = \"microsoft/phi-2\"\n",
    "\n",
    "# Load the unconstrained original model\n",
    "# llm = Syncode(model = model_name, mode='original', max_new_tokens=20)\n",
    "\n",
    "# Load the Syncode augmented model\n",
    "syn_llm = Syncode(model = model_name, grammar=grammar, parse_output_only=True, max_new_tokens=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3f9f3b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "We detected that you are passing `past_key_values` as a tuple and this is deprecated and will be removed in v4.43. Please use an appropriate `Cache` class (https://huggingface.co/docs/transformers/v4.41.3/en/internal/generation_utils#transformers.Cache)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM output:\n",
      "'\\nThe US Independence Day is celebrated on July 4th every year.\\n\\nWhat is the significance'\n",
      "\n",
      "Syncode augmented LLM output:\n",
      "July 4\n"
     ]
    }
   ],
   "source": [
    "inp = \"When is the US independence day?\"\n",
    "\n",
    "# output = llm.infer(inp)[0]\n",
    "# print(f\"LLM output:\\n{repr(output)}\\n\")\n",
    "\n",
    "output = syn_llm.infer(inp)[0]\n",
    "print(f\"Syncode augmented LLM output:\\n{output}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bf95c2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM output:\n",
      "'\\n\\nA:\\n\\nYou can use the following code:\\nimport java.util.Scan'\n",
      "\n",
      "Syncode augmented LLM output:\n",
      "December 25\n"
     ]
    }
   ],
   "source": [
    "inp = \"When is the christmas day?\"\n",
    "\n",
    "# output = llm.infer(inp)[0]\n",
    "# print(f\"LLM output:\\n{repr(output)}\\n\")\n",
    "\n",
    "output = syn_llm.infer(inp)[0]\n",
    "print(f\"Syncode augmented LLM output:\\n{output}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ad2158b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM output:\n",
      "'\\nThe date of the Veterans Day is November 11.\\nWhat is the Veterans Day?\\nThe'\n",
      "\n",
      "Syncode augmented LLM output:\n",
      "November 11\n"
     ]
    }
   ],
   "source": [
    "inp = \"When is the veterans day?\"\n",
    "\n",
    "# output = llm.infer(inp)[0]\n",
    "# print(f\"LLM output:\\n{repr(output)}\\n\")\n",
    "\n",
    "output = syn_llm.infer(inp)[0]\n",
    "print(f\"Syncode augmented LLM output:\\n{output}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
